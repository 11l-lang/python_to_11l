from tokenizer import Token
from typing import List

class SymbolNode:
    token : Token
    #symbol : SymbolBase
    children : List['SymbolNode']# = []
    function_call : bool
    tuple : bool

    def __init__(self, token):
        self.token = token
        self.children = []

    def to_str(self):
        r = ''
        prev_token_end = self.children[0].token.start
        for c in self.children:
            r += source[prev_token_end:c.token.start]
            if c.token.value(source) != 'self': # hack for a while
                r += c.token.value(source)
            prev_token_end = c.token.end
        return r

class ASTNode:
    pass

class ASTNodeWithChildren(ASTNode):
    # children : List['ASTNode'] = [] # OMFG! This actually means static (common for all objects of type ASTNode) variable, not default value of member variable, that was unexpected to me as it contradicts C++11 behavior
    children : List['ASTNode']
    tokeni : int

    def __init__(self):
        self.children = []

    def newlines(self):
        return '' if self.tokeni == 0 else (source[tokens[self.tokeni-2].end:tokens[self.tokeni].start].count("\n")-1) * "\n"

class ASTProgram(ASTNodeWithChildren):
    def to_str(self):
        r = ''
        for c in self.children:
            r += c.to_str(0)
        return r

class ASTExpression(ASTNode):
    expression : SymbolNode

    def to_str(self, indent):
        return ' ' * (indent*3) + self.expression.to_str() + "\n"

class ASTAssignment(ASTNode):
    dest : Token
    expression : SymbolNode

    def to_str(self, indent):
        return ' ' * (indent*3) + self.dest.value(source) + ' = ' + self.expression.to_str() + "\n"

python_types_to_11l = {'int':'Int', 'str':'String', 'List':'Array', 'Tuple':'Tuple'}

class ASTTypeHint(ASTNode):
    var : str
    type : str
    type_args : List[str]

    def to_str(self, indent):
        return ' ' * (indent*3) + python_types_to_11l[self.type] + ('[' + ', '.join(python_types_to_11l[ty] for ty in self.type_args) + ']' if len(self.type_args) else '') + ' ' + self.var + "\n"

class ASTAssignmentWithTypeHint(ASTTypeHint):
    expression : SymbolNode

    def to_str(self, indent):
        return super().to_str(indent)[:-1] + ' = ' + self.expression.to_str() + "\n"

class ASTFunctionDefinition(ASTNodeWithChildren):
    function_name : str
    function_arguments : List[str]# = []

    def __init__(self):
        super().__init__()
        self.function_arguments = []

    def to_str(self, indent):
        r = self.newlines() + ' ' * (indent*3) + 'F ' + (self.function_name if self.function_name != '__init__' else '') \
            + '(' + ", ".join(self.function_arguments if len(self.function_arguments) == 0 or self.function_arguments[0] != 'self' else self.function_arguments[1:]) + ")\n"
        for c in self.children:
            r += c.to_str(indent+1)
        return r

class ASTReturn(ASTNode):
    expression : SymbolNode

    def to_str(self, indent):
        return ' ' * (indent*3) + 'R ' + self.expression.to_str() + "\n"

class ASTClassDefinition(ASTNodeWithChildren):
    base_class_name : str = None
    class_name : str

    def to_str(self, indent):
        r = self.newlines() + ' ' * (indent*3) + 'T ' + self.class_name + ('(' + self.base_class_name + ')' if self.base_class_name and self.base_class_name != 'Exception' else '') + "\n"
        for c in self.children:
            r += c.to_str(indent+1)
        return r

class Error(Exception):
    def __init__(self, message, pos):
        self.message = message
        self.pos = pos

def next_token():
    global token, tokeni, tokensn
    if token == None and tokeni != -1:
        raise Error('no more tokens', len(source))
    tokeni += 1
    if tokeni == len(tokens):
        token = None
        tokensn = None
    else:
        token = tokens[tokeni]
        tokensn = SymbolNode(token)
        #tokensn.symbol = symbol_table["(literal)" if token.is_literal() else "(name)" if token.category == Token.Category.NAME else token.value]

def peek_token(how_much = 1):
    return tokens[tokeni+how_much] if tokeni+how_much < len(tokens) else Token()

def expression():
    r = SymbolNode(token)
    while token != None and token.category not in (Token.Category.STATEMENT_SEPARATOR, Token.Category.DEDENT):
        r.children.append(tokensn)
        next_token()
    return r

def parse_internal(this_node) -> ASTNode:
    global token

    def new_scope_expected():
        if token.value(source) != ':':
            raise Error('expected `:`', tokens[tokeni-1].end)
        next_token()
        assert(token.category == Token.Category.INDENT) # error message ‘expected an indented block’ is already generated by tokenizer, so there is just an assert
        next_token()

    def expected(ch):
        if token.value(source) != ch:
            raise Error('expected `'+ch+'`', token.start)
        next_token()

    def expected_name(what_name):
        next_token()
        if token.category != Token.Category.NAME:
            raise Error('expected ' + what_name, token.start)
        token_value = token.value(source)
        next_token()
        return token_value

    while token != None:
        if token.category == Token.Category.KEYWORD:
            if token.value(source) == 'def':
                node = ASTFunctionDefinition()
                node.tokeni = tokeni
                node.function_name = expected_name('function name')

                if token.value(source) != '(': # )
                    raise Error('expected `(` after function name', token.start) # )(

                next_token()
                while token.value(source) != ')':
                    if token.category != Token.Category.NAME:
                        raise Error('expected function\'s argument name', token.start)
                    node.function_arguments.append(token.value(source))
                    next_token() # ((
                    if token.value(source) not in ',)':
                        raise Error('expected `,` or `)` in function\'s arguments list', token.start)
                    if token.value(source) == ',':
                        next_token()

                next_token()
                new_scope_expected()

                parse_internal(node)

            elif token.value(source) == 'class':
                node = ASTClassDefinition()
                node.tokeni = tokeni
                node.class_name = expected_name('class name')

                if token.value(source) == '(':
                    node.base_class_name = expected_name('base class name')
                    expected(')')

                new_scope_expected()
                parse_internal(node)

            elif token.value(source) == 'return':
                next_token()
                node = ASTReturn()
                node.expression = expression()
                if token != None and token.category == Token.Category.STATEMENT_SEPARATOR:
                    next_token()

            else:
                raise Error('unrecognized statement started with keyword', token.start)

        elif token.category == Token.Category.NAME and peek_token().value(source) == '=':
            node = ASTAssignment()
            node.dest = token
            next_token()
            next_token()
            node.expression = expression()
            assert(token == None or token.category in (Token.Category.STATEMENT_SEPARATOR, Token.Category.DEDENT)) # [-replace with `raise Error` with meaningful error message after first precedent of triggering this assert-]
            if token != None and token.category == Token.Category.STATEMENT_SEPARATOR:
                next_token()

        elif token.category == Token.Category.NAME and peek_token().value(source) == ':': # this is type hint
            var = token.value(source)
            next_token()
            type = expected_name('type name')
            type_args = []
            if token.value(source) == '[':
                next_token()
                while token.value(source) != ']':
                    type_args.append(token.value(source))
                    next_token() # [[
                    if token.value(source) not in ',]':
                        raise Error('expected `,` or `]` in type\'s arguments list', token.start)
                    if token.value(source) == ',':
                        next_token()
                next_token()

            if token != None and token.value(source) == '=':
                node = ASTAssignmentWithTypeHint()
                next_token()
                node.expression = expression()
            else:
                node = ASTTypeHint()
                if not (token == None or token.category in (Token.Category.STATEMENT_SEPARATOR, Token.Category.DEDENT)):
                    raise Error('expected end of statement', token.start)
            node.var = var
            node.type = type
            node.type_args = type_args

            assert(token == None or token.category in (Token.Category.STATEMENT_SEPARATOR, Token.Category.DEDENT)) # [-replace with `raise Error` with meaningful error message after first precedent of triggering this assert-]
            if token != None and token.category == Token.Category.STATEMENT_SEPARATOR:
                next_token()

        elif token.category == Token.Category.DEDENT:
            next_token()
            return this_node

        else:
            node = ASTExpression()
            node.expression = expression()
            assert(token == None or token.category in (Token.Category.STATEMENT_SEPARATOR, Token.Category.DEDENT)) # [-replace with `raise Error` with meaningful error message after first precedent of triggering this assert-]
            if token != None and token.category == Token.Category.STATEMENT_SEPARATOR:
                next_token()

        this_node.children.append(node)

    return this_node

def parse(tokens_, source_):
    global tokens, source, tokeni, token
    tokens = tokens_
    source = source_
    if len(tokens):
        tokeni = -1
        token = None
        next_token()
    p = ASTProgram()
    return parse_internal(p)
